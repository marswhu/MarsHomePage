<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="author" content="MARS">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name=keywords content="Mang Ye" , "Ye Mang" , "叶茫" , "WHU" , "Wuhan University" , "武汉大学" , "MARS" , "marswhu"
        , "MARS WHU">

    <title>Projects</title>

    <link href="../../static/bootstrap/css/bootstrap.css" rel="stylesheet">
    <link href="../../static/xin.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css">

</head>

<body>

    <nav class="navbar navbar-inverse navbar-fixed-top">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <span class="navbar-brand">
                    <font color="#ffffff">MARS</a></font>
                </span>
            </div>
            <div class="navbar-collapse collapse">
                <ul class="nav navbar-nav">
                    <li><a href="../../../index.html">Home</a></li>
                    <li><a href="../../publications/index.htm"> Publications </a></li>
                    <li class="active"><a href="../index.htm"> Projects </a></li>
                    <li><a href="../../team/index.htm">Team</a></li>
                    <li><a href="../../teaching/index.htm">Teaching</a></li>
                    <li><a href="../../service/index.htm">Service</a></li>
                </ul>
            </div>
        </div>
    </nav>

    <div class="container" style="margin-top: 50px;">
        <!-- <p>
            <br />
            <i class="bi-arrow-left-circle"></i><small><a href="#">Back</a></small>
        </p> -->
        <h2>AI-Generated Content (AIGC)</h2>
        <div class="row-project">
            <div class="span12">
                <section>
                    <p>AI-Generated Content (AIGC) involves the use of artificial intelligence to create various forms
                        of content, such as text, images, audio, and video. This technology enables the automated
                        generation of creative works, enhancing productivity and enabling new forms of expression. AIGC
                        has significant applications in industries like marketing, entertainment, and education,
                        streamlining content creation processes and providing personalized experiences.
                    </p>
                    <p> We mainly focus on the editing of person images by utilizing different data modalities.</p>
                </section>
            </div>
        </div>

        <p>
            <i class="bi-box-arrow-in-left"></i><small><a style="text-decoration: none;" href="javascript:history.back(-1)">
                    <b>Back</b> </a></small>
        </p>

        <div class="page-header">
            <h3><i>Highlight</i></h3>
        </div>

        <div class="row-fluid">
            <div class="span3">
                <div class="thumbnail">
                    <img class="scale-img" src="../images/AIGC/AAAI24_TexFit.png" alt="">
                </div>
            </div>
            <div class="span9">
                <div class="pub-entry">
                    <div class="pub-info">
                        <div class="pub-title"><strong>TexFit: Text-Driven Fashion Image Editing with Diffusion
                                Models</strong></div>
                        <div class="pub-authors"> Tongxin Wang, <u>Mang Ye*</u></div>
                        <div class="pub-venue"><i>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI),
                                2024.</i>
                        </div>

                        <br>
                        We propose a text-driven fashion image editing method
                        using diffusion models, which only using the text as the
                        initial generation condition, and could achieve close to
                        the real effect of fashion image generation. We propose an editing region location model based
                        on the text prompt to explicitly locate the editing region. We also create a new DFMM-Spotlight
                        dataset, which is an image-region-text pair dataset that enables fnegrained text-guided local
                        image editing.

                        <div class="pub-description">
                            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/28885/29682" target="_blank"><span
                                    class="label_download">Paper</span></a>
                            <a href="https://github.com/tongxin-wang/TexFit" target="_blank"><span
                                    class="label_download">Code</span></a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <hr>

        <p></p>
        </section>

        <div align="center">
            <small>Copyright &copy 2024 <a href="https://marswhu.github.io/">Multimedia Analysis & Reasoning (MARS)
                    Lab</a></small>
            <br>
            <small><a href="https://www.whu.edu.cn/">Wuhan University 武汉大学</a></small>
        </div>
    </div>


    <script src="../../static/jquery.js"></script>
    <script src="../../static/bootstrap/js/bootstrap.js"></script>
</body>

</html>