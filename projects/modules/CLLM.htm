<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="author" content="MARS">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name=keywords content="Mang Ye" , "Ye Mang" , "叶茫" , "WHU" , "Wuhan University" , "武汉大学" , "MARS" , "marswhu"
        , "MARS WHU">

    <title>Projects</title>

    <link href="../../static/bootstrap/css/bootstrap.css" rel="stylesheet">
    <link href="../../static/xin.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css">

</head>

<body>

    <nav class="navbar navbar-inverse navbar-fixed-top">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <span class="navbar-brand">
                    <font color="#ffffff">MARS</a></font>
                </span>
            </div>
            <div class="navbar-collapse collapse">
                <ul class="nav navbar-nav">
                    <li><a href="../../../index.html">Home</a></li>
                    <li><a href="../../publications/index.htm"> Publications </a></li>
                    <li class="active"><a href="../index.htm"> Projects </a></li>
                    <li><a href="../../team/index.htm">Team</a></li>
                    <li><a href="../../teaching/index.htm">Teaching</a></li>
                    <li><a href="../../service/index.htm">Service</a></li>
                </ul>
            </div>
        </div>
    </nav>

    <div class="container" style="margin-top: 50px;">
        <!-- <p>
            <br />
            <i class="bi-arrow-left-circle"></i><small><a href="#">Back</a></small>
        </p> -->
        <h2>Continual Learning</h2>
        <div class="row-project">
            <div class="span12">
                <section>
                    <p>Continual Learning focuses on enabling models to learn and adapt to new data
                        over time without forgetting previously learned information. It is crucial for maintaining the
                        performance of AI systems in dynamic environments, allowing them to evolve as new tasks and data
                        emerge, without the need for full retraining from scratch.
                    </p>
                    <p> We aim to explore robust learning paradigms for continual learning and its applications in
                        large models.</p>
                </section>
            </div>
        </div>

        <p>
            <i class="bi-box-arrow-in-left"></i><small><a style="text-decoration: none;" href="javascript:history.back(-1)">
                    <b>Back</b> </a></small>
        </p>

        <div class="page-header">
            <h3><i>Highlight</i></h3>
        </div>

        <div class="row-fluid">
            <div class="span3">
                <div class="thumbnail">
                    <img class="scale-img" src="../images/CLLM/NeurIPS24_PRL.png" alt="">
                </div>
            </div>
            <div class="span9">
                <div class="pub-entry">
                    <div class="pub-info">
                        <div class="pub-title"><strong>Prospective Representation Learning for
                                Non-Exemplar Class-Incremental Learning</strong></div>
                        <div class="pub-authors">Wuxuan Shi, <u>Mang Ye*</u></div>
                        <div class="pub-venue"><i>Thirty-seventh Conference on Neural Information Processing Systems
                                (NeurIPS), 2024.</i>
                        </div>

                        <br>
                        We propose a Prospective Representation
                        Learning (PRL) scheme to prepare the model for handling conflicts in advance.
                        In the base phase, we squeeze the embedding distribution of the current classes
                        to reserve space for forward compatibility with future classes. In the incremental
                        phase, we make the new class features away from the saved prototypes of old
                        classes in a latent space while aligning the current embedding space with the latent
                        space when updating the model. The new class features are clustered in the
                        reserved space to minimize the shock of the new classes on the former classes.

                        <div class="pub-description">
                            <a href="../../publications/files/NeurIPS24_PRL.pdf" target="_blank"><span
                                    class="label_download">Paper</span></a>
                            <a href="https://github.com/ShiWuxuan/NeurIPS2024-PRL/" target="_blank"><span
                                    class="label_download">Code</span></a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <hr>

        <div class="row-fluid">
            <div class="span3">
                <div class="thumbnail">
                    <img class="scale-img" src="../images/CLLM/ICCV23_NECIL.jpg" alt="">
                </div>
            </div>
            <div class="span9">
                <div class="pub-entry">
                    <div class="pub-info">
                        <div class="pub-title"><strong>Prototype Reminiscence and Augmented Asymmetric Knowledge
                                Aggregation for Non-Exemplar Class-Incremental Learning</strong></div>
                        <div class="pub-authors">Wuxuan Shi, <u>Mang Ye*</u></div>
                        <div class="pub-venue"><i>International Conference on Computer Vision (ICCV), 2023.</i>
                        </div>

                        <br>
                        We propose a novel prototype reminiscence mechanism that incorporates the previous class
                        prototypes with arriving new class features to dynamically
                        reshape old class feature distributions thus preserving the decision boundaries
                        of previous tasks. In addition, to improve the model generalization on both newly arriving
                        classes and old classes, we contribute an augmented asymmetric knowledge aggregation approach,
                        which aggregates the
                        overall knowledge of the current task and extracts the valuable knowledge of the past tasks, on
                        top of self-supervised label augmentation.

                        <div class="pub-description">
                            <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Prototype_Reminiscence_and_Augmented_Asymmetric_Knowledge_Aggregation_for_Non-Exemplar_Class-Incremental_ICCV_2023_paper.pdf"
                                target="_blank"><span class="label_download">Paper</span></a>
                            <a href="https://shiwuxuan.github.io/PRAKA-project/" target="_blank"><span
                                    class="label_download">Code</span></a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <hr>

        <p></p>
        </section>

        <div align="center">
            <small>Copyright &copy 2024 <a href="https://marswhu.github.io/">Multimedia Analysis & Reasoning (MARS)
                    Lab</a></small>
            <br>
            <small><a href="https://www.whu.edu.cn/">Wuhan University 武汉大学</a></small>
        </div>
    </div>


    <script src="../../static/jquery.js"></script>
    <script src="../../static/bootstrap/js/bootstrap.js"></script>
</body>

</html>